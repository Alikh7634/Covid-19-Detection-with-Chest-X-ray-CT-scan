{
 "cells": [
  {
   "attachments": {
    "cyborg-color.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cyborg-color.png](attachment:cyborg-color.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from torch.utils.data import DataLoader, random_split, WeightedRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.4.0+cu121\n",
      "CUDA Available: True\n",
      "CUDA Version: 12.1\n",
      "GPU Name: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Covid = 'C:\\\\Users\\\\Ali khatami\\\\Desktop\\\\Uni\\\\Challenge2\\\\Dt\\\\Covid CT scan\\\\COVID'\n",
    "Non_covid = 'C:\\\\Users\\\\Ali khatami\\\\Desktop\\\\Uni\\\\Challenge2\\\\Dt\\\\Covid CT scan\\\\non-COVID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (256, 256)\n",
    "\n",
    "def read_img(folder_path, category):\n",
    "    image = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "            img = cv2.resize(img, image_size)\n",
    "            image.append((img, category))\n",
    "\n",
    "    return image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  # Convert to grayscale (if needed)\n",
    "    transforms.Resize((64, 64)),                  # Resize to (64x64)\n",
    "    transforms.ToTensor(),                        # Convert to a PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize to [-1, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"C:\\\\Users\\\\Ali khatami\\\\Desktop\\\\Uni\\\\Challenge2\\\\Dt\\\\Covid CT scan\\\\Images\"\n",
    "dataset = datasets.ImageFolder(root=data_path, transform=transform)\n",
    "batch_size = 8\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size= batch_size, shuffle= True)\n",
    "val_loader = DataLoader(val_dataset, batch_size= batch_size, shuffle= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7025901675224304\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "nn.Conv2d(1, 32, kernel_size=3),\n",
    "nn.ReLU(),\n",
    "nn.MaxPool2d(kernel_size= 2, stride= 2),\n",
    "nn.Conv2d(32, 64, kernel_size= 3),\n",
    "nn.ReLU(),\n",
    "nn.Dropout(0.5),\n",
    "nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "nn.Flatten(),\n",
    "nn.Linear(64 * 14 * 14, 128),\n",
    "nn.ReLU(),\n",
    "nn.Dropout(0.5),\n",
    "nn.Linear(128, 1),\n",
    "nn.Sigmoid()\n",
    ").to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = Adam(model.parameters(), lr= 0.001)\n",
    "\n",
    "img_size = (64, 64)\n",
    "batch_size= 8\n",
    "\n",
    "inputs = torch.randn(batch_size, 1, img_size[0], img_size[1]).to(device)\n",
    "labels = torch.rand(batch_size, 1).to(device)\n",
    "\n",
    "outputs = model(inputs)\n",
    "loss = criterion(outputs, labels)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "print(f\"loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Train Loss: 0.1454, Val Loss: 0.2414, Val Accuracy: 0.01%\n",
      "Epoch [2/15], Train Loss: 0.1281, Val Loss: 0.2266, Val Accuracy: 0.01%\n",
      "Epoch [3/15], Train Loss: 0.1249, Val Loss: 0.2214, Val Accuracy: 0.01%\n",
      "Epoch [4/15], Train Loss: 0.1398, Val Loss: 0.2504, Val Accuracy: 0.01%\n",
      "Epoch [5/15], Train Loss: 0.1282, Val Loss: 0.2218, Val Accuracy: 0.01%\n",
      "Epoch [6/15], Train Loss: 0.1032, Val Loss: 0.2185, Val Accuracy: 0.01%\n",
      "Epoch [7/15], Train Loss: 0.1090, Val Loss: 0.2176, Val Accuracy: 0.01%\n",
      "Epoch [8/15], Train Loss: 0.1098, Val Loss: 0.2202, Val Accuracy: 0.01%\n",
      "Epoch [9/15], Train Loss: 0.1236, Val Loss: 0.2663, Val Accuracy: 0.01%\n",
      "Epoch [10/15], Train Loss: 0.1124, Val Loss: 0.2138, Val Accuracy: 0.01%\n",
      "Epoch [11/15], Train Loss: 0.1017, Val Loss: 0.2135, Val Accuracy: 0.01%\n",
      "Epoch [12/15], Train Loss: 0.1285, Val Loss: 0.2269, Val Accuracy: 0.01%\n",
      "Epoch [13/15], Train Loss: 0.1081, Val Loss: 0.2104, Val Accuracy: 0.01%\n",
      "Epoch [14/15], Train Loss: 0.0972, Val Loss: 0.2081, Val Accuracy: 0.01%\n",
      "Epoch [15/15], Train Loss: 0.0998, Val Loss: 0.2175, Val Accuracy: 0.01%\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, labels in data_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_val_loss += loss.item()\n",
    "\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    avg_val_loss = running_val_loss / len(val_loader)\n",
    "    val_accuracy = correct / (total * 100)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f}, \"\n",
    "          f\"Val Loss: {avg_val_loss:.4f}, \"\n",
    "          f\"Val Accuracy: {val_accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
